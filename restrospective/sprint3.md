## 3rd Sprint SPG Project RETROSPECTIVE (Team R1)

### PROCESS MEASURES

#### Macro statistics

- Number of stories committed vs done

  4 stories committed and 3 stories completely done.

- Total points committed vs done

  309 points committed and 227 points done.

- Nr of hours planned vs spent (as a team)

   67 hours planned vs 56h 30m spent.

  

#### Detailed statistics

| id   | Stroy                                         | #Tasks | Points | Hours est. | Hour Actual |
| ---- | --------------------------------------------- | ------ | ------ | ---------- | ----------- |
| 9    | Report availability                           | 1      | 90     | 4h         | 1h          |
| 10   | Check orders pending cancelation              | 1      | 88     | 2h         | 1h          |
| 17   | Confirm booking                               | 1      | 82     | 6h         | 4.5h        |
| 0    | Fixing issues, various implementation,testing | 16     | 49     | 55h        | 52h         |

- Hours per task

  3h 07m average per task, 12.60 standard deviation

  Total task estimation error ratio:  67/58.5=1.14

------



### QUALITY MEASURES

#### Unit Testing:

Estimated 8 hrs for the testing in general and about the same time was spent, but not everything intended to be completed was actually fully done. Regardless of this, a coverage of about 70% was achieved.

#### Code review:

Estimated a total of 2:30 hours, so half an hour per person. A total of 4:40 were spent given the large amount of new functionalities and features that were implemented.

#### Technical Debt management:

We spent 2 hours on fixing bugs and security issues which sonar given. For this part, sonar was estimated to take 4 and a half hours. But bugs and security issues are relatively basic problems, and there are some false positives, so we quickly completed fixing work.

#### SonarQube ratings

|   **Reliability**   |        **A-0 bugs**         |
| :-----------------: | :-------------------------: |
| **Maintainability** |   **A - 52 Code Smells**    |
|    **Security**     |  **A - 0 Vulnerabilities**  |
| **Security Review** | **A - 0 Security Hotspots** |



------



### ASSESSMENT

- What caused your errors in estimation (if any)?

We overestimated the stories effort and underestimated the bug fixing, testing and technical debt.

- What lessons did you learn (both positive and negative) in this sprint?

Since we managed to do a lot of stories, the negative lesson we learnt is that we will have to manage better the technical debt for the next week because the more stories you do, the more things to fix there are.

- Which improvement goals set in the previous retrospective were you able to achieve?

First of all, we gave a lot of importance to the issues that the stakeholders found during the presentation of the last sprint, so we began very early to look at those problems and we managed to fix them all. Also, we got a better organization and tried to maximize our efforts altogether.

- Which ones were you not able to achieve? Why?

We weren’t able to successfully implement 100% of the calendar because we had to focus on a big amount of stories.

- Improvement goals for the next sprint and how to achieve them (technical tasks, team coordination, etc.)

We have to complete the stories relative to the calendar and to make all the front end working, also we might have to re-organize a bit our organization as we have been focusing more on the frontend than on the backend up to now, instead in this future sprint we need to focus more on making everything work on the back end side.

- One thing you are proud of as a Team!!

We were proud to handle the whole platform we built until now pretty good and functioning. The content and the functions are coherent and together they draw a clear picture of the working project itself and that’s the result of a well organized team.

------

